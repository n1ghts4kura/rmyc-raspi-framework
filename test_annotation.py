#
# test_annotation.py
# è§†è§‰è¯†åˆ«å™¨æµ‹è¯•ç¨‹åº
#
# @author n1ghts4kura
#

import time
import cv2
from src.recognizer import Recognizer

def main():
    print("=" * 60)
    print("RMYC Raspi Framework - Recognizer æµ‹è¯•ç¨‹åº")
    print("=" * 60)
    print("åŠŸèƒ½ï¼šæµ‹è¯• YOLOv8 ç›®æ ‡æ£€æµ‹çš„å®æ—¶æ€§èƒ½å’Œå‡†ç¡®æ€§")
    print("æ“ä½œï¼šæŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
    print("=" * 60)
    print()
    
    # è·å–å•ä¾‹å®ä¾‹
    print("ğŸ“· æ­£åœ¨åˆå§‹åŒ–è¯†åˆ«å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰...")
    recognizer = Recognizer.get_instance()
    
    # ç­‰å¾…åˆå§‹åŒ–å®Œæˆï¼ˆåŒ…å«æ¨¡å‹é¢„çƒ­ï¼‰
    print("â³ ç­‰å¾…è¯†åˆ«å™¨å°±ç»ªï¼ˆé¦–æ¬¡å¯åŠ¨éœ€è¦æ¨¡å‹é¢„çƒ­ï¼Œçº¦ 5-10 ç§’ï¼‰...")
    if not recognizer.wait_until_initialized(timeout=30):
        print("âŒ åˆå§‹åŒ–è¶…æ—¶ï¼ˆ30ç§’ï¼‰ï¼Œé€€å‡ºç¨‹åº")
        return
    
    # æ£€æŸ¥è¿è¡ŒçŠ¶æ€
    if not recognizer.is_running():
        print("âŒ è¯†åˆ«å™¨æœªæ­£å¸¸è¿è¡Œï¼Œé€€å‡ºç¨‹åº")
        return
    
    # æ˜¾ç¤ºè¯¦ç»†çŠ¶æ€
    status = recognizer.get_status()
    print("âœ… è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆï¼ˆæ¨¡å‹å·²é¢„çƒ­ï¼‰")
    print(f"   - æ‘„åƒå¤´ï¼š{'å·²æ‰“å¼€' if status['camera_opened'] else 'æœªæ‰“å¼€'}")
    print(f"   - æ¨¡å‹ï¼š{'å·²åŠ è½½å¹¶é¢„çƒ­' if status['model_loaded'] else 'æœªåŠ è½½'}")
    print(f"   - é‡‡é›†çº¿ç¨‹ï¼š{'è¿è¡Œä¸­' if status['capture_thread_alive'] else 'æœªè¿è¡Œ'}")
    print(f"   - æ¨ç†çº¿ç¨‹ï¼š{'è¿è¡Œä¸­' if status['infer_thread_alive'] else 'æœªè¿è¡Œ'}")
    print(f"   - æ¨ç†æ¨¡å¼ï¼šæœ€å¤§é€Ÿåº¦æ¨¡å¼ï¼ˆæ— å¸§ç‡é™åˆ¶ï¼‰")
    print()
    
    print("ğŸ¬ å¼€å§‹å®æ—¶æ£€æµ‹...")
    print("-" * 60)
    
    frame_count = 0
    detect_count = 0
    start_time = time.time()
    last_print_time = start_time
    
    try:
        while True:
            # æ˜¾ç¤ºæ¨ç†ç»“æœï¼ˆå¦‚æœå¯ç”¨äº†æ³¨é‡Šå¸§ï¼‰
            recognizer.imshow()
            
            # æ£€æŸ¥é€€å‡ºé”®
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nğŸ‘‹ ç”¨æˆ·è¯·æ±‚é€€å‡º")
                break
            
            # è·å–æ£€æµ‹ç»“æœ
            boxes = recognizer.get_latest_boxes()
            status = recognizer.get_status()
            
            frame_count += 1
            if boxes:
                detect_count += 1
            
            # æ¯ç§’è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
            current_time = time.time()
            if current_time - last_print_time >= 1.0:
                elapsed = current_time - start_time
                avg_fps = frame_count / elapsed if elapsed > 0 else 0
                detect_rate = (detect_count / frame_count * 100) if frame_count > 0 else 0
                
                print(f"[{int(elapsed):4d}s] "
                      f"ä¸»å¾ªç¯å¸§æ•°: {frame_count:5d} | "
                      f"æ¨ç†å¸§æ•°: {status['predict_frame_count']:5d} | "
                      f"ä¸¢å¼ƒå¸§æ•°: {status['dropped_frame_count']:5d} | "
                      f"å®é™…æ¨ç†FPS: {status['actual_inference_fps']:5.2f} | "
                      f"æ£€æµ‹ç‡: {detect_rate:5.1f}% | "
                      f"å½“å‰ç›®æ ‡: {len(boxes):2d}")
                
                # å¦‚æœæœ‰æ£€æµ‹åˆ°ç›®æ ‡ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                if boxes and len(boxes) <= 3:  # æœ€å¤šæ˜¾ç¤º3ä¸ªç›®æ ‡çš„è¯¦ç»†ä¿¡æ¯
                    for idx, box in enumerate(boxes, 1):
                        x1, y1, x2, y2 = box
                        width = x2 - x1
                        height = y2 - y1
                        center_x = (x1 + x2) / 2
                        center_y = (y1 + y2) / 2
                        print(f"      ç›®æ ‡ {idx}: ä¸­å¿ƒ({center_x:.0f}, {center_y:.0f}) "
                              f"å°ºå¯¸({width:.0f}x{height:.0f})")
                
                last_print_time = current_time
            
            time.sleep(0.01)  # æ§åˆ¶ä¸»å¾ªç¯é¢‘ç‡ï¼Œé¿å… CPU å ç”¨è¿‡é«˜
            
    except KeyboardInterrupt:
        print("\nâš ï¸  æ£€æµ‹åˆ° Ctrl+C ä¿¡å·")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œæ—¶å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        final_status = recognizer.get_status()
        avg_fps = frame_count / total_time if total_time > 0 else 0
        detect_rate = (detect_count / frame_count * 100) if frame_count > 0 else 0
        
        print()
        print("=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»è¿è¡Œæ—¶é—´: {total_time:.1f} ç§’")
        print(f"ä¸»å¾ªç¯æ€»å¸§æ•°: {frame_count}")
        print(f"ä¸»å¾ªç¯å¹³å‡ FPS: {avg_fps:.2f}")
        print()
        print("ğŸ”¬ æ¨ç†æ€§èƒ½ç»Ÿè®¡")
        print("-" * 60)
        print(f"æ¨ç†æ€»å¸§æ•°: {final_status['predict_frame_count']}")
        print(f"ä¸¢å¼ƒæ€»å¸§æ•°: {final_status['dropped_frame_count']}")
        print(f"å®é™…æ¨ç†å¸§ç‡: {final_status['actual_inference_fps']} FPS ï¼ˆæœ€å¤§é€Ÿåº¦ï¼‰")
        
        # è®¡ç®—æ¨ç†æ•ˆç‡
        if final_status['predict_frame_count'] > 0:
            inference_efficiency = (final_status['predict_frame_count'] / 
                                   (final_status['predict_frame_count'] + final_status['dropped_frame_count']) * 100)
            print(f"æ¨ç†æ•ˆç‡: {inference_efficiency:.2f}%")
            print(f"   ï¼ˆæ¨ç†å¸§æ•° / (æ¨ç†å¸§æ•° + ä¸¢å¼ƒå¸§æ•°) Ã— 100ï¼‰")
            print()
            print(f"ğŸ’¡ æ€§èƒ½æŒ‡æ ‡ï¼š")
            print(f"   - å®é™…æ¨ç† FPS è¶Šé«˜è¶Šå¥½ï¼ˆå—ç¡¬ä»¶å’Œæ¨¡å‹é™åˆ¶ï¼‰")
            print(f"   - ä¸¢å¼ƒå¸§æ•°æ­£å¸¸ï¼ˆæ™ºèƒ½è·³å¸§ç­–ç•¥ï¼Œç¡®ä¿å¤„ç†æœ€æ–°å›¾åƒï¼‰")
        
        print()
        print("ğŸ¯ ç›®æ ‡æ£€æµ‹ç»Ÿè®¡")
        print("-" * 60)
        print(f"æ£€æµ‹åˆ°ç›®æ ‡çš„å¸§æ•°: {detect_count}")
        print(f"ç›®æ ‡æ£€æµ‹ç‡: {detect_rate:.2f}%")
        print("=" * 60)
        print("ğŸ‘‹ ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main()
