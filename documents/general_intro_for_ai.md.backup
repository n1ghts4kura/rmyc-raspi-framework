# RMYC Raspi Framework 项目架构文档（供 AI 协作参考）

> **文档用途**：本文档详细描述项目的技术架构、核心机制和设计决策，供 AI 在架构级任务、深度开发、模块设计时参考。
> 
> **阅读建议**：
> - 首次接触项目：完整阅读"背景与目标"、"框架架构"章节
> - 架构级任务：重点阅读"核心架构设计"、"关键机制"章节
> - 模块开发：查阅对应的模块详细说明（如"串口通信机制"、"技能系统"）

---

## 项目背景与目标

### 赛事定位
- **RMYC（机甲大师空地协同对抗赛）**：国内领先的青少年机器人赛事，培养工程实践能力
- **对战模式**：4v4 战术射击，自主研发/改装机器人，通过发射弹丸削弱护甲并摧毁基地
- **自动阶段**：机器人可自主运行，选手只能提前配置或触发技能

### 框架目标
1. **统一控制层**：在树莓派侧构建技能框架，集中调度各子系统
2. **高效通讯**：通过 UART 监听键鼠事件，转化为技能触发指令
3. **视觉自瞄**：基于 YOLO + OpenCV 实现目标检测与云台自动瞄准
4. **可扩展技能体系**：标准生命周期管理，支持自主动作编排Raspi Framework 面向 AI 协作的项目简介

## 目标与背景

- **赛事定位**：机甲大师空地协同对抗赛（RMYC）旨在成为国内最受欢迎的青少年机器人赛事，通过先进的科学教育理念培养未来工程师。
- **对战模式**：每场对战为 4v4 战术射击，包含自主研发或改装机器人。双方通过发射弹丸、削弱护甲和摧毁基地决出胜负。
- **自动阶段**：比赛允许机器人在特定阶段自主运行，选手只能提前配置或触发技能，这也是框架中“技能”系统存在的原因。

### 兵种职责

| 兵种 | 核心任务 | 技术要点 |
|------|---------|----------|
| **步兵机器人** | 激活能量机关、巡线、自瞄射击 | 机器学习、云台控制、视觉识别、巡线算法 |
| **工程机器人** | 获取弹药、搬运大弹丸、复活队友 | 夹爪机构、升降控制、角度/位置闭环 |
| **空中机器人** | 投掷大弹丸攻击基地 | 无人机编程、飞行控制、轻量化设计 |

---

## 技术栈与设计选择

| 技术领域 | 选型 | 理由 |
|---------|------|------|
| **开发语言** | Python 3.10+ | 语法直观、生态丰富、快速迭代 |
| **视觉识别** | YOLO + OpenCV | 预训练模型、实时检测、易于集成 |
| **通讯协议** | UART 串口 | 可靠性高、硬件支持广泛 |
| **调试工具** | Prompt Toolkit REPL | 彩色输出、异步交互、命令历史 |
| **日志系统** | 自研 Logger（单例模式） | 彩色分级输出、DEBUG 模式切换 |

---

## 核心架构设计

### 三层架构

```
┌─────────────────────────────────────────────┐
│          应用层 (Application Layer)         │
│  • main.py: 主循环、事件分发、技能调度      │
│  • repl.py: 交互式调试工具                  │
└──────────────────┬──────────────────────────┘
                   │
┌──────────────────▼──────────────────────────┐
│        业务逻辑层 (Business Logic Layer)    │
│  • skill/: 技能框架（定义、管理、执行）     │
│  • aimassistant/: 自瞄系统（目标选择）      │
│  • recognizer.py: 视觉识别（YOLO 推理）     │
└──────────────────┬──────────────────────────┘
                   │
┌──────────────────▼──────────────────────────┐
│      硬件抽象层 (Hardware Abstraction)      │
│  • bot/conn.py: 串口通信（队列、线程）      │
│  • bot/gimbal.py: 云台控制                  │
│  • bot/chassis.py: 底盘运动                 │
│  • bot/blaster.py: 发射器控制               │
│  • bot/game_msg.py: 赛事消息解析            │
└─────────────────────────────────────────────┘
```

### 关键数据流

```
键鼠事件 → 串口传输 → game_msg_process() → SkillManager
                                             ↓
                              invoke_skill_by_key / cancel_skill_by_key
                                             ↓
                              技能执行线程（BaseSkill）
                                             ↓
                              硬件控制命令（gimbal / chassis / blaster）
                                             ↓
                              串口发送 → 机器人执行
```

### 性能敏感区域 ⚡

**识别标准**（满足任一条件即为性能敏感）：
1. **高频调用**：主循环或控制循环 >10 Hz
2. **实时性要求**：响应延迟直接影响功能表现
3. **线程密集**：多线程、异步操作、共享资源
4. **I/O 密集**：频繁的硬件 I/O、网络 I/O

**当前性能敏感模块**：
- **视觉识别**：双线程设计（采集 + 推理），ONNX 优化
- **自瞄系统**：目标选择器 20 Hz 调用，角度计算需快速精确
- **串口通信**：后台接收线程，非阻塞 + 双队列设计

**优化原则**：
- ✅ 修改前评估是否引入阻塞操作
- ✅ 优先保证功能正确性，再优化性能
- ⚠️ 非热路径（配置加载、日志）不需过度优化

## 现有技术栈与设计选择

- **语言**：Python —— 语法直观、生态丰富，便于快速迭代并兼顾初学者上手。
- **视觉识别**：YOLO（使用预训练模型 `model/yolov8n.pt`）结合 OpenCV 进行图像采集、预处理与目标识别。
- **通讯**：UART 串口 + 自研 `conn` 模块，实现串口读写、命令缓冲与后台队列。
- **交互工具**：Prompt Toolkit 驱动的异步串口 REPL（位于 `src/repl.py`），提供彩色输出、后台接收线程、命令分发队列，便于调试与临场运维。

## 框架模块概览（基于 `src/` 目录）

- `main.py`：应用入口。完成串口初始化、SDK 模式切换、技能注册与主循环事件分发。
- `logger.py`：彩色控制台日志工具，封装单例 `Logger` 与便捷函数（`LOG.info(...)` 等），默认 DEBUG 模式便于调试。
- `recognizer.py`：双线程 YOLO 识别器，实现采集/推理解耦、最新检测结果缓存与可视化接口。
- `repl.py`：基于 Prompt Toolkit 的串口 REPL，集成彩色日志、后台接收线程、分号命令队列与键鼠透传调试能力。
- `bot/`：硬件抽象层。
  - `conn.py`：UART 打开/关闭、后台接收线程、命令/行级队列。
  - `sdk.py`：DJI RoboMaster SDK 模式切换与初始握手封装。
  - `chassis.py`、`gimbal.py`、`blaster.py` 等：底盘、云台、发射机构控制。
  - `game_msg.py`：赛事消息解析为结构化字典，供技能决策使用。
- `skill/`：技能框架。
  - `base_skill.py`：技能对象定义、线程化执行、状态管理、错误标记。
  - `manager.py`：技能注册、按键状态切换、互斥调用与取消。
  - `example_skill.py`：按键 `w` 绑定示例，展示日志打印、延时与武器触发流程。
- `model/`：视觉算法单元的占位目录，可放置后续策略模型或推理辅助脚本。
- 根目录下 `test_*.py`：快速回归测试/样例，用于验证主流程、机器人控制接口或 REPL 行为。

> 建议 AI 在分析代码时，关注技能框架与通讯模块的接口约束。技能应尽量无状态或明确管理状态，以便在自动阶段安全运行。

## 自瞄模块预期流程

1. 采集图像：调用 OpenCV 从摄像头获取帧。
2. 目标检测：通过 YOLO 推理识别敌方关键信息（机器人装甲板、基地能量机关等）。
3. 位姿估计：根据检测框计算云台目标角度，结合 IMU/编码器反馈实现闭环控制。
4. 发射决策：在满足安全与策略条件下指挥步兵机器人开火。

## 编码风格与约定

- **日志优先**：统一通过 `import logger as LOG` 使用，遵循 `LOG.debug/info/warning/error` 级别划分；必要时调用 `LOG.exception` 捕获栈。
- **类型提示**：核心模块均提供类型注解，新增函数请保持注解与文档字符串同步，便于静态分析与 AI 理解数据流。
- **线程模型**：技能执行使用 `threading.Thread` 异步调用；视觉识别使用双线程架构。新增线程需明确停止信号与资源回收。
- **命令协议**：串口命令均为分号分隔的短字符串，读取时通过 `get_serial_command_nowait()` 完成，避免阻塞主循环。
- **技能约束**：`BaseSkill` 自动将绑定键转为小写；在 `SkillManager` 注册时必须保证键位唯一，并负责在技能结束时调用 `skill.async_cancel()`。
- **文件组织**：模块命名使用小写+下划线；新增硬件模块置于 `bot/`，技能放在 `skill/`，视觉算法放在 `recognizer.py` 或其子模块。

## 技能扩展流程（示例）

1. 在 `skill/` 下创建新文件或复制 `example_skill.py` 模板。
2. 编写 `BaseSkill` 实例，设置 `binding_key`（务必小写）、`invoke_func` 与描述性 `name`。
3. 在技能函数中：
   - 使用 `LOG` 记录状态与错误；
   - 通过 `bot/` 模块调用底层硬件；
   - 如需长时任务，妥善处理中断或异常并调用 `skill.set_errored()`。
4. 在 `main.py`（或未来的技能注册中心）中 `skill_manager.add_skill(new_skill)`。
5. 运行 `python src/main.py` 或 REPL 工具验证按键触发逻辑。

## 调试与测试工具

- **REPL**：`python src/repl.py` 进入交互式调试，实时查看串口输出与发送命令。
- **日志配置**：在 `logger.py` 中切换 `DEBUG_MODE` 或调用 `logger.set_debug_mode()` 来调整日志粒度。
- **测试脚本**：`test_main.py`、`test_bot.py` 等包含最小化验证用例，扩展功能时建议补充断言与模拟串口数据。
- **视觉调试**：`Recognizer.imshow()` 支持在桌面环境中可视化最新推理结果；`get_fps_info()` 可快速检查性能瓶颈。

## 通讯交互模式

- **输入**：客户端监听键鼠事件，将事件打包为 UART 指令发送给机器人。
- **输出**：机器人通过串口反馈状态（如血量、弹药、位姿），异步写入 REPL 的日志面板。
- **命令结构**：采用分号分隔的指令队列（`get_serial_command_nowait()`），保证多命令顺序执行。

## 面向 AI 协作者的建议

- **分层理解**：从赛事战略目标→技能策略→硬件驱动→通讯/视觉管线逐层梳理，确保设计决策在各层一致。
- **接口优先**：扩展新功能前先查阅 `bot/` 与 `skill/` 现有接口，保持命名与调用语义一致；必要时在文档中同步约束。
- **测试优先**：为关键路径添加/更新测试或 REPL 演练脚本，提交前至少跑一遍核心脚本确保串口与线程逻辑稳定。
- **性能与安全**：评估串口带宽、线程安全、机械安全。自动开火前应核验传感器状态，必要时增加互锁与兜底日志。
- **协作透明**：新增模块请在 `documents/intro_for_ai.md` 或相关 README 中补充说明，降低后续 AI/开发者介入成本。

## 未来工作入口

- 完善视觉识别数据集与模型训练流程。
- 构建仿真环境，模拟自动阶段决策逻辑。
- 增加多机器人协同策略模块（如战术决策 AI、任务调度）。
- 完成跨平台部署脚本和 CI/CD 流水线，确保框架可重复部署。

---
本文件旨在帮助 AI 快速理解项目范围、技术栈与协作方式。建议每次提交前更新本说明，保持与项目演进同步，以提升自动化开发效率。
