#
# recognizer.py
#
# @author n1ghts4kura
#

import typing as t
import threading
import time
import os
import cv2
import queue
import numpy as np
from ultralytics import YOLO

IF_IMSHOW = False # æ˜¯å¦æ˜¾ç¤ºçª—å£
IF_ANNOTATE = False # æ˜¯å¦ç”Ÿæˆå¸¦æ³¨é‡Šçš„å¸§ï¼ˆç”¨äºè°ƒè¯•å±•ç¤ºï¼‰

try:
    import src.logger as logger
except ImportError:
    import logger

class Recognizer:
    """
    å•æ‘„åƒå¤´ã€å•æ¨¡å‹è¯†åˆ«å™¨
    
    é‡‡ç”¨åŒçº¿ç¨‹è®¾è®¡ï¼šé‡‡é›†çº¿ç¨‹ä¸“æ³¨é«˜é¢‘é‡‡é›†ï¼Œæ¨ç†çº¿ç¨‹å¤„ç†æœ€æ–°å¸§ã€‚
    
    **å•ä¾‹æ¨¡å¼**ï¼šå…¨å±€åªå…è®¸å­˜åœ¨ä¸€ä¸ª Recognizer å®ä¾‹ã€‚
    
    ç”¨æ³•ï¼š
        # è·å–å•ä¾‹å®ä¾‹
        recog = Recognizer.get_instance()
        recog.wait_until_initialized()
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
        if recog.is_running():
            boxes = recog.get_latest_boxes()
        
        # æˆ–ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        with Recognizer.get_instance() as recog:
            recog.wait_until_initialized()
            boxes = recog.get_latest_boxes()
    """
    
    _instance: t.Optional['Recognizer'] = None
    _instance_lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        """å®ç°å•ä¾‹æ¨¡å¼ï¼šç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹"""
        if cls._instance is None:
            with cls._instance_lock:
                # åŒé‡æ£€æŸ¥é”å®š
                if cls._instance is None:
                    cls._instance = super(Recognizer, cls).__new__(cls)
                    cls._instance._singleton_initialized = False
        return cls._instance

    def __init__(
        self,
        cam_width: int = 320,
        cam_height: int = 480,
        imshow_width: int = 160,
        imshow_height: int = 240,
        cam_fps: float = 60.0,
        target_inference_fps: int = 15,  # ï¿½ ç›®æ ‡æ¨ç†å¸§ç‡ï¼ˆä»…ç”¨äºæ€§èƒ½å¯¹æ¯”ï¼Œä¸é™åˆ¶å®é™…é€Ÿåº¦ï¼‰
        model_input_size: int = 320,      # ğŸ”¥ YOLO è¾“å…¥å°ºå¯¸ï¼ˆ256/320/416ï¼‰
    ) -> None:
        # é¿å…é‡å¤åˆå§‹åŒ–
        if self._singleton_initialized:
            return
        
        self._singleton_initialized = True
        # æ‘„åƒå¤´é…ç½®
        self.cam_width = cam_width
        self.cam_height = cam_height
        self.cam_fps = cam_fps

        # æ¨ç†é…ç½®
        self.target_inference_fps = target_inference_fps  # ï¿½ ç›®æ ‡æ¨ç†å¸§ç‡ï¼ˆç”¨äºæ€§èƒ½å¯¹æ¯”ï¼‰
        self.model_input_size = model_input_size  # ğŸ”¥ YOLO è¾“å…¥å°ºå¯¸

        # æ˜¾ç¤ºé…ç½®
        self.imshow_width = imshow_width
        self.imshow_height = imshow_height
        
        # æ¨¡å‹é…ç½®
        self.model_path = "./model/yolov8n.onnx"  # ğŸ”¥ ä½¿ç”¨ ONNX æ ¼å¼ï¼ˆæ¯” NCNN æ›´ç¨³å®šï¼‰
        self.conf: float = 0.3  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
        self.iou: float = 0.7
        self.device: str = "cpu"  # ğŸ”¥ æ¨ç†è®¾å¤‡ï¼ˆcpu / 0 / 1 ç­‰ï¼‰
        
        # è¿è¡ŒçŠ¶æ€
        self._initialized: bool = False
        self._initialized_lock = threading.Lock()
        
        # ç¡¬ä»¶èµ„æº
        self.cap: t.Optional[cv2.VideoCapture] = None
        self.model: t.Optional[YOLO] = None
        
        # æ˜¾ç¤ºå¸§ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        self.current_annotated_frame: t.Optional[cv2.typing.MatLike] = None
        
        # çº¿ç¨‹é—´é€šä¿¡
        self._frame_queue: queue.Queue = queue.Queue(maxsize=2)  # å¢åŠ é˜Ÿåˆ—å¤§å°
        self._capture_thread: t.Optional[threading.Thread] = None
        self._infer_thread: t.Optional[threading.Thread] = None
        self._stop_event = threading.Event()
        
        # ç»“æœå­˜å‚¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self._lock = threading.Lock()
        self._latest_boxes: t.List[t.List[float]] = []

        # æ€§èƒ½ç»Ÿè®¡
        self._predict_frame_count = 0
        self._dropped_frame_count = 0
        self._last_inference_time = 0
        self._inference_start_time = 0  # æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å¹³å‡ FPSï¼‰

        self.start()

    @classmethod
    def get_instance(cls, **kwargs) -> 'Recognizer':
        """
        è·å– Recognizer å•ä¾‹å®ä¾‹ã€‚
        
        Args:
            **kwargs: ä»…åœ¨é¦–æ¬¡åˆ›å»ºå®ä¾‹æ—¶æœ‰æ•ˆï¼Œåç»­è°ƒç”¨ä¼šå¿½ç•¥è¿™äº›å‚æ•°ã€‚
        
        Returns:
            Recognizer: å•ä¾‹å®ä¾‹
        
        Example:
            >>> recog = Recognizer.get_instance(cam_width=640, cam_height=480)
            >>> # åç»­è°ƒç”¨è¿”å›åŒä¸€å®ä¾‹
            >>> recog2 = Recognizer.get_instance()  # recog2 is recog -> True
        """
        if cls._instance is None:
            return cls(**kwargs)
        return cls._instance

    def is_running(self) -> bool:
        """
        æ£€æŸ¥è¯†åˆ«å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œï¼ˆé‡‡é›†çº¿ç¨‹å’Œæ¨ç†çº¿ç¨‹éƒ½åœ¨æ´»è·ƒçŠ¶æ€ï¼‰ã€‚
        
        Returns:
            bool: å¦‚æœé‡‡é›†çº¿ç¨‹å’Œæ¨ç†çº¿ç¨‹éƒ½åœ¨è¿è¡Œï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
        
        Example:
            >>> recog = Recognizer.get_instance()
            >>> recog.start()
            >>> if recog.is_running():
            ...     boxes = recog.get_latest_boxes()
        """
        # æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€
        with self._initialized_lock:
            if not self._initialized:
                return False
        
        # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦å­˜æ´»ä¸”æœªåœæ­¢
        capture_alive = (
            self._capture_thread is not None and 
            self._capture_thread.is_alive() and 
            not self._stop_event.is_set()
        )
        
        infer_alive = (
            self._infer_thread is not None and 
            self._infer_thread.is_alive() and 
            not self._stop_event.is_set()
        )
        
        return capture_alive and infer_alive
    
    def get_status(self) -> dict:
        """
        è·å–è¯†åˆ«å™¨çš„è¯¦ç»†è¿è¡ŒçŠ¶æ€ã€‚
        
        Returns:
            dict: åŒ…å«ä»¥ä¸‹å­—æ®µçš„çŠ¶æ€å­—å…¸
                - initialized: æ˜¯å¦å·²åˆå§‹åŒ–
                - running: æ˜¯å¦æ­£åœ¨è¿è¡Œ
                - capture_thread_alive: é‡‡é›†çº¿ç¨‹æ˜¯å¦å­˜æ´»
                - infer_thread_alive: æ¨ç†çº¿ç¨‹æ˜¯å¦å­˜æ´»
                - stop_event_set: åœæ­¢äº‹ä»¶æ˜¯å¦å·²è®¾ç½®
                - queue_size: å½“å‰é˜Ÿåˆ—å¤§å°
                - latest_boxes_count: æœ€æ–°æ£€æµ‹åˆ°çš„ç›®æ ‡æ•°é‡
                - predict_frame_count: å·²æ¨ç†çš„æ€»å¸§æ•°
                - dropped_frame_count: å·²ä¸¢å¼ƒçš„å¸§æ•°
                - target_inference_fps: ç›®æ ‡æ¨ç†å¸§ç‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                - actual_inference_fps: å®é™…æ¨ç†å¸§ç‡
        
        Example:
            >>> recog = Recognizer.get_instance()
            >>> status = recog.get_status()
            >>> print(f"è¿è¡ŒçŠ¶æ€: {status['running']}, æ£€æµ‹ç›®æ ‡æ•°: {status['latest_boxes_count']}")
        """
        with self._initialized_lock:
            initialized = self._initialized
        
        capture_alive = self._capture_thread is not None and self._capture_thread.is_alive()
        infer_alive = self._infer_thread is not None and self._infer_thread.is_alive()
        
        # è®¡ç®—å®é™…æ¨ç†å¸§ç‡ï¼ˆåŸºäºå¯åŠ¨ä»¥æ¥çš„å¹³å‡å€¼ï¼‰
        actual_fps = 0.0
        if self._inference_start_time > 0 and self._predict_frame_count > 0:
            elapsed = time.time() - self._inference_start_time
            if elapsed > 0:
                # åŸºäºæ€»æ¨ç†å¸§æ•°è®¡ç®—å¹³å‡å¸§ç‡
                actual_fps = self._predict_frame_count / elapsed
        
        return {
            "initialized": initialized,
            "running": self.is_running(),
            "capture_thread_alive": capture_alive,
            "infer_thread_alive": infer_alive,
            "stop_event_set": self._stop_event.is_set(),
            "queue_size": self._frame_queue.qsize(),
            "latest_boxes_count": len(self._latest_boxes),
            "camera_opened": self.cap is not None and (self.cap.isOpened() if self.cap else False),
            "model_loaded": self.model is not None,
            "predict_frame_count": self._predict_frame_count,
            "dropped_frame_count": self._dropped_frame_count,
            "target_inference_fps": self.target_inference_fps,
            "actual_inference_fps": round(actual_fps, 2),
        }


    def __del__(self):
        self.stop()
        self.clean_up()


    def wait_until_initialized(self, timeout: float = 120) -> bool:
        """
        é˜»å¡ç­‰å¾…ï¼Œç›´åˆ°è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆæˆ–è¶…æ—¶ã€‚
        
        Args:
            timeout (float): æœ€å¤§ç­‰å¾…æ—¶é—´ï¼Œå•ä½ç§’ã€‚é»˜è®¤120ç§’ã€‚
        Returns:
            bool: å¦‚æœåœ¨è¶…æ—¶å‰åˆå§‹åŒ–å®Œæˆï¼Œè¿”å›Trueï¼›å¦åˆ™è¿”å›Falseã€‚
        """
        start_time = time.time()
        while True:
            with self._initialized_lock:
                if self._initialized:
                    return True
            if time.time() - start_time > timeout:
                return False
            time.sleep(0.1)


    def start(self) -> bool:
        """
        å¯åŠ¨è¯†åˆ«å™¨ï¼Œåˆå§‹åŒ–æ‘„åƒå¤´ä¸æ¨¡å‹ï¼Œå¹¶å¼€å¯åå°çº¿ç¨‹ã€‚
        
        Returns:
            bool: å¦‚æœæˆåŠŸå¯åŠ¨è¿”å› Trueï¼Œå¦‚æœå·²ç»åœ¨è¿è¡Œåˆ™è¿”å› False
        """
        # âœ… é˜²æ­¢é‡å¤å¯åŠ¨ï¼ˆçº¿ç¨‹å®‰å…¨æ£€æŸ¥ï¼‰
        if self._capture_thread is not None and self._capture_thread.is_alive():
            logger.warning("è¯†åˆ«å™¨å·²ç»åœ¨è¿è¡Œä¸­ï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
            return False
        
        if not self._init_camera() or not self._init_model():
            logger.error("åˆå§‹åŒ–å¤±è´¥")
            raise Exception("æ‘„åƒå¤´æˆ–æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            # return False

        self._stop_event.clear()
        
        # å¯åŠ¨é‡‡é›†çº¿ç¨‹
        self._capture_thread = threading.Thread(target=self._capture_loop, daemon=True)
        self._capture_thread.start()
        
        # å¯åŠ¨æ¨ç†çº¿ç¨‹
        self._infer_thread = threading.Thread(target=self._infer_loop, daemon=True)
        self._infer_thread.start()

        # âœ… ä¸ç«‹å³è®¾ç½® _initialized = True
        # ç­‰å¾…æ¨ç†çº¿ç¨‹å®Œæˆæ¨¡å‹é¢„çƒ­åè®¾ç½®
        
        logger.info("è¯†åˆ«å™¨çº¿ç¨‹å·²å¯åŠ¨ï¼Œæ­£åœ¨é¢„çƒ­æ¨¡å‹...")
        return True


    def stop(self) -> None:
        """
        åœæ­¢è¯†åˆ«å™¨ï¼Œç»ˆæ­¢åå°çº¿ç¨‹ã€‚
        """
        self._stop_event.set()
        
        if self._capture_thread and self._capture_thread.is_alive():
            self._capture_thread.join(timeout=2.0)
        if self._infer_thread and self._infer_thread.is_alive():
            self._infer_thread.join(timeout=2.0)
        
        with self._initialized_lock:
            self._initialized = False
        
        logger.info("è¯†åˆ«å™¨å·²åœæ­¢")


    def clean_up(self) -> None:
        """é‡Šæ”¾èµ„æºï¼Œå…³é—­æ‘„åƒå¤´ä¸çª—å£ã€‚"""
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        cv2.destroyAllWindows()


    def get_latest_boxes(self) -> t.List[t.List[float]]:
        """
        è·å–æœ€æ–°çš„è¾¹ç•Œæ¡†åˆ—è¡¨ã€‚
        Returns:
            List[List[float]]: æœ€æ–°çš„è¾¹ç•Œæ¡†åˆ—è¡¨ï¼Œæ¯ä¸ªè¾¹ç•Œæ¡†æ ¼å¼ä¸º [x1, y1, x2, y2]ã€‚
        """
        with self._lock:
            return list(self._latest_boxes)


    def _init_camera(self) -> bool:
        """åˆå§‹åŒ–æ‘„åƒå¤´ï¼Œè®¾ç½®åˆ†è¾¨ç‡ä¸å¸§ç‡ã€‚"""
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            logger.error("æ‘„åƒå¤´æœªæ‰“å¼€")
            return False

        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šå¯ç”¨ç¡¬ä»¶åŠ é€Ÿ
        try:
            self.cap.set(cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY)
        except:
            logger.warning("ç¡¬ä»¶åŠ é€Ÿè®¾ç½®å¤±è´¥ï¼ˆå¯èƒ½ä¸æ”¯æŒï¼‰")
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘ç¼“å†²åŒºå»¶è¿Ÿ
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # è®¾ç½®åˆ†è¾¨ç‡å’Œå¸§ç‡
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.cam_width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.cam_height)
        self.cap.set(cv2.CAP_PROP_FPS, self.cam_fps)
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨ MJPEG æ ¼å¼å‡å°‘è§£ç å¼€é”€
        try:
            self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M','J','P','G')) # type: ignore
        except:
            logger.warning("MJPEG æ ¼å¼è®¾ç½®å¤±è´¥")

        # æµ‹è¯•æ‘„åƒå¤´æ˜¯å¦æ­£å¸¸å·¥ä½œ
        for i in range(10):
            ret, _ = self.cap.read()
        if not ret: # type: ignore
            logger.error("æ‘„åƒå¤´æœªè¯»å–åˆ°å¸§")
            self.cap.release()
            self.cap = None
            return False

        logger.info(f"æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆ: {self.cam_width}x{self.cam_height}@{self.cam_fps}fps")
        return True


    def _init_model(self) -> bool:
        """åˆå§‹åŒ–YOLOæ¨¡å‹ï¼ˆONNX Runtime åç«¯ï¼‰ã€‚"""
        try:
            # åˆå§‹åŒ–æ¨¡å‹
            logger.info(f"ğŸ“¦ æ­£åœ¨åŠ è½½ ONNX æ¨¡å‹: {self.model_path}")
            self.model = YOLO(self.model_path, task="detect")
            logger.info("âœ… ONNX Runtime åç«¯å·²åŠ è½½ï¼ˆCPU ä¼˜åŒ–ï¼‰")
            
            # ä½¿ç”¨è™šæ‹Ÿå›¾åƒé¢„çƒ­
            dummy_frame = np.zeros((self.cam_height, self.cam_width, 3), dtype=np.uint8)
            logger.info("ğŸ”¥ é¢„çƒ­æ¨ç† (3æ¬¡)...")
            for i in range(3):
                self.model.predict(dummy_frame, verbose=False)
            
            logger.info(f"âœ… YOLO æ¨¡å‹å·²åŠ è½½å¹¶é¢„çƒ­å®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.error("è¯·ç¡®ä¿å·²å¯¼å‡º ONNX æ¨¡å‹: python tools/export_onnx_optimized.py")
            self.model = None
            return False


    def _capture_loop(self) -> None:
        """é‡‡é›†çº¿ç¨‹ï¼šä¸“æ³¨é«˜é¢‘é‡‡é›†ï¼Œç›´æ¥å°†å¸§æ”¾å…¥é˜Ÿåˆ—"""
        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šç»‘å®šåˆ° CPU æ ¸å¿ƒ 0
        try:
            import os
            os.sched_setaffinity(0, {0}) # type: ignore
            logger.info("é‡‡é›†çº¿ç¨‹å¯åŠ¨ï¼ˆç»‘å®š CPU 0ï¼‰")
        except Exception as e:
            logger.info(f"é‡‡é›†çº¿ç¨‹å¯åŠ¨ï¼ˆCPU ç»‘å®šå¤±è´¥: {e}ï¼‰")
        
        while not self._stop_event.is_set():
            if self.cap is None:
                time.sleep(0.01)
                continue
                
            ret, frame = self.cap.read()
            if ret:
                try:
                    # å¦‚æœé˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒæ—§å¸§
                    if self._frame_queue.full():
                        try:
                            self._frame_queue.get_nowait()
                        except queue.Empty:
                            pass
                    self._frame_queue.put_nowait(frame)
                except queue.Full:
                    pass  # é˜Ÿåˆ—æ»¡æ—¶é™é»˜ä¸¢å¼ƒå½“å‰å¸§
            else:
                time.sleep(0.01)  # é‡‡é›†å¤±è´¥æ—¶çŸ­æš‚ä¼‘çœ 
        
        logger.info("é‡‡é›†çº¿ç¨‹é€€å‡º")


    def _infer_loop(self) -> None:
        """
        æ¨ç†çº¿ç¨‹ï¼šæ¨¡å‹é¢„çƒ­ + æ™ºèƒ½è·³å¸§ç­–ç•¥ + æœ€å¤§é€Ÿåº¦æ¨ç†
        
        æµç¨‹ï¼š
        1. ç­‰å¾…é¦–å¸§ç”¨äºé¢„çƒ­
        2. ä½¿ç”¨çœŸå®å¸§é¢„çƒ­æ¨¡å‹ï¼ˆ3 æ¬¡æ¨ç†ï¼‰
        3. æ¸…ç©ºé¢„çƒ­æœŸé—´çš„æ—§å¸§
        4. è®¾ç½®å°±ç»ªæ ‡å¿—
        5. å¼€å§‹æ­£å¸¸æ¨ç†ï¼ˆæ™ºèƒ½è·³å¸§ + æœ€å¤§é€Ÿåº¦ï¼‰
        """
        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šç»‘å®šåˆ° CPU æ ¸å¿ƒ 2-3ï¼ˆæ€§èƒ½æ ¸å¿ƒï¼‰
        try:
            import os
            os.sched_setaffinity(0, {2, 3}) # type: ignore
            logger.info("æ¨ç†çº¿ç¨‹å¯åŠ¨ï¼ˆç»‘å®š CPU 2-3ï¼‰")
        except Exception as e:
            logger.info(f"æ¨ç†çº¿ç¨‹å¯åŠ¨ï¼ˆCPU ç»‘å®šå¤±è´¥: {e}ï¼‰")
        
        # ============================================================
        # é˜¶æ®µ 1ï¼šæ¨¡å‹é¢„çƒ­ï¼ˆè§£å†³é¦–æ¬¡æ¨ç†å»¶è¿Ÿé—®é¢˜ï¼‰
        # ============================================================
        logger.info("ç­‰å¾…é¦–å¸§ç”¨äºæ¨¡å‹é¢„çƒ­...")
        
        # ç­‰å¾…é‡‡é›†çº¿ç¨‹æä¾›é¦–å¸§
        warmup_frame = None
        while warmup_frame is None and not self._stop_event.is_set():
            try:
                warmup_frame = self._frame_queue.get(timeout=0.5)
            except queue.Empty:
                continue
        
        if warmup_frame is None:
            logger.error("æœªèƒ½è·å–é¢„çƒ­å¸§ï¼Œæ¨ç†çº¿ç¨‹é€€å‡º")
            return
        
        # ä½¿ç”¨çœŸå®å¸§é¢„çƒ­æ¨¡å‹ï¼ˆ3 æ¬¡æ¨ç†ï¼‰
        logger.info("ğŸ”¥ å¼€å§‹æ¨¡å‹é¢„çƒ­ï¼ˆé¦–æ¬¡æ¨ç†éœ€è¦ 5-10 ç§’ï¼Œè¯·ç¨å€™ï¼‰...")
        try:
            for i in range(3):
                self.model.predict(warmup_frame, conf=self.conf, iou=self.iou, verbose=False) # type: ignore
                logger.info(f"   é¢„çƒ­è¿›åº¦: {i+1}/3")
            logger.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼")
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # æ¸…ç©ºé¢„çƒ­æœŸé—´ç§¯ç´¯çš„æ—§å¸§
        cleared_frames = 0
        while not self._frame_queue.empty():
            try:
                self._frame_queue.get_nowait()
                cleared_frames += 1
            except queue.Empty:
                break
        logger.info(f"å·²æ¸…ç©ºé¢„çƒ­æœŸé—´çš„ {cleared_frames} å¸§æ—§æ•°æ®")
        
        # è®¾ç½®å°±ç»ªæ ‡å¿—ï¼ˆwait_until_initialized ä¼šè¿”å›ï¼‰
        with self._initialized_lock:
            self._initialized = True
        
        # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å¹³å‡ FPSï¼‰
        self._inference_start_time = time.time()
        logger.info("ğŸš€ è¯†åˆ«å™¨å®Œå…¨å°±ç»ªï¼Œå¼€å§‹å®æ—¶æ¨ç†ï¼")
        
        # ============================================================
        # é˜¶æ®µ 2ï¼šæ­£å¸¸æ¨ç†å¾ªç¯ï¼ˆæ™ºèƒ½è·³å¸§ + æœ€å¤§é€Ÿåº¦ï¼‰
        # ============================================================
        
        while not self._stop_event.is_set():
            try:
                # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šæ¸…ç©ºé˜Ÿåˆ—ï¼Œåªå–æœ€æ–°å¸§
                frame = None
                dropped_count = 0
                
                # å–å‡ºæ‰€æœ‰æ—§å¸§ï¼Œåªä¿ç•™æœ€æ–°çš„
                while not self._frame_queue.empty():
                    try:
                        frame = self._frame_queue.get_nowait()
                        dropped_count += 1
                    except queue.Empty:
                        break
                
                # è‡³å°‘ä¸¢å¼ƒä¸€å¸§æ‰ç®—æœ‰æ•ˆï¼ˆå› ä¸ºæˆ‘ä»¬å–äº†æœ€æ–°å¸§ï¼‰
                if dropped_count > 0:
                    dropped_count -= 1
                    self._dropped_frame_count += dropped_count
                
                # å¦‚æœæœ‰å¸§ï¼Œç«‹å³è¿›è¡Œæ¨ç†ï¼ˆæ— å»¶è¿Ÿï¼‰
                if frame is not None:
                    self._process_frame(frame)
                    # æ›´æ–°æœ€åæ¨ç†æ—¶é—´æˆ³
                    self._last_inference_time = time.time()
                else:
                    # é˜Ÿåˆ—ä¸ºç©ºæ—¶çŸ­æš‚ä¼‘çœ ï¼Œé¿å…ç©ºè½¬æµªè´¹ CPU
                    time.sleep(0.001)  # 1ms ä¼‘çœ 
                    
            except Exception as e:
                logger.error(f"æ¨ç†å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(0.01)
        
        logger.info("æ¨ç†çº¿ç¨‹é€€å‡º")


    def _process_frame(self, frame: cv2.typing.MatLike) -> None:
        """å¤„ç†å•å¸§ï¼šæ¨ç† + ç”Ÿæˆæ³¨é‡Šå¸§ + æ›´æ–°ç»“æœ"""
        if self.model is None:
            return
            
        try:
            # æ‰§è¡Œæ¨ç†
            results = self.model.predict(
                source=frame,
                conf=self.conf,
                iou=self.iou,
                verbose=False  # å‡å°‘æ—¥å¿—è¾“å‡º
            )
            
            # ç”Ÿæˆå¸¦æ³¨é‡Šçš„å¸§ç”¨äºæ˜¾ç¤º
            if IF_ANNOTATE:
                self.current_annotated_frame = results[0].plot()

            # æå–è¾¹ç•Œæ¡†
            boxes = self._extract_boxes(results[0])
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœ
            with self._lock:
                self._latest_boxes = boxes

            self._predict_frame_count += 1
                
        except Exception as e:
            logger.error(f"å¸§å¤„ç†å¤±è´¥: {e}")


    def _extract_boxes(self, result) -> t.List[t.List[float]]:
        """ä»YOLOç»“æœä¸­æå–è¾¹ç•Œæ¡†"""
        try:
            if result.boxes is None or len(result.boxes) == 0:
                return []
            return result.boxes.xyxy.cpu().numpy().tolist()
        except Exception as e:
            logger.error(f"è¾¹ç•Œæ¡†æå–å¤±è´¥: {e}")
            return []


    def imshow(self, win_name: str = "Recognizer", wait: int = 1) -> None:
        """
        è°ƒè¯•ç”¨ï¼šå±•ç¤ºæ¨ç†å¸§ï¼ˆå¸¦æ³¨é‡Šï¼‰æˆ–åŸå§‹å¸§ã€‚
        """

        if not IF_IMSHOW:
            return

        # ä¼˜å…ˆæ˜¾ç¤ºæ¨ç†å¸§ï¼Œå¦åˆ™å°è¯•è·å–é˜Ÿåˆ—ä¸­çš„åŸå§‹å¸§
        if self.current_annotated_frame is not None:
            imshow_frame = cv2.resize(self.current_annotated_frame, (self.imshow_width, self.imshow_height))
            cv2.imshow(win_name, imshow_frame)
            cv2.waitKey(wait)
        elif not self._frame_queue.empty():
            try:
                frame = self._frame_queue.queue[0]  # æŸ¥çœ‹é˜Ÿåˆ—ä¸­çš„å¸§ä½†ä¸å–å‡º
                cv2.imshow(win_name, frame)
                cv2.waitKey(wait)
            except:
                logger.warning("æ— å¯æ˜¾ç¤ºå¸§")
        else:
            logger.warning("æ— å¯æ˜¾ç¤ºå¸§")
