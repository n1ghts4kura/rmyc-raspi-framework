#
# recognizer.py
#
# @author n1ghts4kura
#

import cv2
import time
import queue
import threading
import numpy as np
import typing as t
from ultralytics import YOLO
from ultralytics.engine.results import Boxes

IF_IMSHOW = False # æ˜¯å¦æ˜¾ç¤ºçª—å£
IF_ANNOTATE = False # æ˜¯å¦ç”Ÿæˆå¸¦æ³¨é‡Šçš„å¸§ï¼ˆç”¨äºè°ƒè¯•å±•ç¤ºï¼‰

try:
    import src.logger as logger
    import src.config as config
except ImportError:
    import logger
    import config

class Recognizer:
    """
    è§†è§‰è¯†åˆ«å™¨

    ä¸»è¦æ¥å£:
    - get_instance(): è·å–å•ä¾‹å®ä¾‹
    - start(): å¯åŠ¨è¯†åˆ«å™¨
    - stop(): åœæ­¢è¯†åˆ«å™¨
    - wait_until_initialized(): é˜»å¡ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
    - is_running(): æ£€æŸ¥è¯†åˆ«å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ
    - get_latest_boxes(): è·å–æœ€æ–°çš„è¾¹ç•Œæ¡†åˆ—è¡¨
    - get_status(): è·å–è¯†åˆ«å™¨çš„è¯¦ç»†è¿è¡ŒçŠ¶æ€
    """
    
    # å•ä¾‹æ¨¡å¼ å®ç°
    _instance: t.Optional['Recognizer'] = None
    _instance_lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._instance_lock:
                # åŒé‡æ£€æŸ¥é”å®š
                if cls._instance is None:
                    cls._instance = super(Recognizer, cls).__new__(cls)
        return cls._instance


    def __init__(
        self,
        cam_width: int = 480,
        cam_height: int = 320,
        imshow_width: int = 240,
        imshow_height: int = 160,
        cam_fps: float = 60.0,
        # target_inference_fps: int = 15,  # ï¿½ ç›®æ ‡æ¨ç†å¸§ç‡ï¼ˆä»…ç”¨äºæ€§èƒ½å¯¹æ¯”ï¼Œä¸é™åˆ¶å®é™…é€Ÿåº¦ï¼‰
        # model_input_size: int = 320,      # ğŸ”¥ YOLO è¾“å…¥å°ºå¯¸ï¼ˆ256/320/416ï¼‰
    ) -> None:
        """
        Args:
            cam_width: æ‘„åƒå¤´é‡‡é›†å®½åº¦
            cam_height: æ‘„åƒå¤´é‡‡é›†é«˜åº¦
            imshow_width: æ˜¾ç¤ºçª—å£å®½åº¦
            imshow_height: æ˜¾ç¤ºçª—å£é«˜åº¦
            cam_fps: æ‘„åƒå¤´å¸§ç‡
            target_inference_fps: ç›®æ ‡æ¨ç†å¸§ç‡
            model_input_size: YOLO è¾“å…¥å°ºå¯¸
        """
        # é¿å…é‡å¤åˆå§‹åŒ–ï¼ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰ cam_width å±æ€§ï¼‰
        if hasattr(self, 'cam_width'):
            return
        
        # æ‘„åƒå¤´é…ç½®
        self.cam_width = cam_width
        self.cam_height = cam_height
        self.cam_fps = cam_fps

        # æ¨ç†é…ç½®
        # self.target_inference_fps = target_inference_fps  # ï¿½ ç›®æ ‡æ¨ç†å¸§ç‡ï¼ˆç”¨äºæ€§èƒ½å¯¹æ¯”ï¼‰
        # self.model_input_size = model_input_size  # ğŸ”¥ YOLO è¾“å…¥å°ºå¯¸

        # æ˜¾ç¤ºé…ç½®
        self.imshow_width = imshow_width
        self.imshow_height = imshow_height
        
        # æ¨¡å‹é…ç½®
        self.model_path = config.YOLO_MODEL_PATH
        self.conf: float = 0.3    # ç½®ä¿¡åº¦é˜ˆå€¼
        self.iou: float = 0.7     # IOU é˜ˆå€¼
        self.device: str = "cpu"  # æ¨ç†è®¾å¤‡ï¼ˆcpu / 0 / 1 ç­‰ï¼‰
        
        # è¿è¡ŒçŠ¶æ€
        self._initialized: bool = False
        
        # ç¡¬ä»¶èµ„æº
        self.cap: t.Optional[cv2.VideoCapture] = None
        self.model: t.Optional[YOLO] = None
        
        # æ˜¾ç¤ºå¸§ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        self.current_annotated_frame: t.Optional[cv2.typing.MatLike] = None
        
        # çº¿ç¨‹é—´é€šä¿¡
        self._frame_queue: queue.Queue = queue.Queue(maxsize=2)  # å¢åŠ é˜Ÿåˆ—å¤§å°
        self._capture_thread: t.Optional[threading.Thread] = None
        self._infer_thread: t.Optional[threading.Thread] = None
        self._stop_event = threading.Event()
        
        # çŠ¶æ€é”ï¼šä¿æŠ¤ _initialized å’Œ _latest_boxes
        self._state_lock = threading.Lock()
        
        # ç»“æœå­˜å‚¨
        self._latest_boxes: Boxes = Boxes(np.empty((0, 6)), orig_shape=(self.cam_height, self.cam_width))  # åˆå§‹åŒ–ä¸ºç©º Boxes å¯¹è±¡

        # æ€§èƒ½ç»Ÿè®¡
        self._predict_frame_count = 0
        self._dropped_frame_count = 0
        self._last_inference_time = 0
        self._inference_start_time = 0  # æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å¹³å‡ FPSï¼‰

        self.start()


    @classmethod
    def get_instance(cls, **kwargs) -> 'Recognizer':
        """
        è·å– Recognizer å•ä¾‹å®ä¾‹ã€‚
        
        Args:
            **kwargs: ä»…åœ¨é¦–æ¬¡åˆ›å»ºå®ä¾‹æ—¶æœ‰æ•ˆï¼Œåç»­è°ƒç”¨ä¼šå¿½ç•¥è¿™äº›å‚æ•°ã€‚
        """
        if cls._instance is None:
            return cls(**kwargs)
        return cls._instance


    def _is_thread_alive(self, thread: t.Optional[threading.Thread]) -> bool:
        """
        æ£€æŸ¥é‡‡é›†/æ¨ç†çº¿ç¨‹ æ˜¯å¦å­˜æ´»ä¸”æœªåœæ­¢ã€‚
        """

        return (
            thread is not None and 
            thread.is_alive() and 
            not self._stop_event.is_set()
        )

    
    def is_running(self) -> bool:
        """
        æ£€æŸ¥è¯†åˆ«å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œï¼ˆé‡‡é›†çº¿ç¨‹å’Œæ¨ç†çº¿ç¨‹éƒ½åœ¨æ´»è·ƒçŠ¶æ€ï¼‰ã€‚
        
        Returns:
            bool: å¦‚æœé‡‡é›†çº¿ç¨‹å’Œæ¨ç†çº¿ç¨‹éƒ½åœ¨è¿è¡Œï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
        """

        # æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€
        with self._state_lock:
            if not self._initialized:
                return False
        
        # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦å­˜æ´»ä¸”æœªåœæ­¢
        return (
            self._is_thread_alive(self._capture_thread) and 
            self._is_thread_alive(self._infer_thread)
        )

    
    def get_status(self) -> dict:
        """
        è·å–è¯†åˆ«å™¨çš„è¯¦ç»†è¿è¡ŒçŠ¶æ€ã€‚
        
        Returns:
            dict: åŒ…å«ä»¥ä¸‹å­—æ®µçš„çŠ¶æ€å­—å…¸
                - initialized: æ˜¯å¦å·²åˆå§‹åŒ–
                - running: æ˜¯å¦æ­£åœ¨è¿è¡Œ
                - capture_thread_alive: é‡‡é›†çº¿ç¨‹æ˜¯å¦å­˜æ´»
                - infer_thread_alive: æ¨ç†çº¿ç¨‹æ˜¯å¦å­˜æ´»
                - stop_event_set: åœæ­¢äº‹ä»¶æ˜¯å¦å·²è®¾ç½®
                - queue_size: å½“å‰é˜Ÿåˆ—å¤§å°
                - latest_boxes_count: æœ€æ–°æ£€æµ‹åˆ°çš„ç›®æ ‡æ•°é‡
                - predict_frame_count: å·²æ¨ç†çš„æ€»å¸§æ•°
                - dropped_frame_count: å·²ä¸¢å¼ƒçš„å¸§æ•°
                - target_inference_fps: ç›®æ ‡æ¨ç†å¸§ç‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                - actual_inference_fps: å®é™…æ¨ç†å¸§ç‡
        """

        with self._state_lock:
            initialized = self._initialized
        
        capture_alive = self._is_thread_alive(self._capture_thread)
        infer_alive = self._is_thread_alive(self._infer_thread)
        
        # è®¡ç®—å®é™…æ¨ç†å¸§ç‡ï¼ˆåŸºäºå¯åŠ¨ä»¥æ¥çš„å¹³å‡å€¼ï¼‰
        actual_fps = 0.0
        if self._inference_start_time > 0 and self._predict_frame_count > 0:
            elapsed = time.time() - self._inference_start_time
            if elapsed > 0:
                # åŸºäºæ€»æ¨ç†å¸§æ•°è®¡ç®—å¹³å‡å¸§ç‡
                actual_fps = self._predict_frame_count / elapsed
        
        return {
            "initialized": initialized,
            "running": self.is_running(),
            "capture_thread_alive": capture_alive,
            "infer_thread_alive": infer_alive,
            "stop_event_set": self._stop_event.is_set(),
            "queue_size": self._frame_queue.qsize(),
            "latest_boxes_count": len(self._latest_boxes),
            "camera_opened": self.cap is not None and (self.cap.isOpened() if self.cap else False),
            "model_loaded": self.model is not None,
            "predict_frame_count": self._predict_frame_count,
            "dropped_frame_count": self._dropped_frame_count,
            "actual_inference_fps": round(actual_fps, 2),
        }


    def __del__(self):
        self.stop()
        self.clean_up()


    def wait_until_initialized(self, timeout: float = 120) -> bool:
        """
        é˜»å¡ç­‰å¾…ï¼Œç›´åˆ°è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆæˆ–è¶…æ—¶ã€‚
        
        Args:
            timeout (float): æœ€å¤§ç­‰å¾…æ—¶é—´ï¼Œå•ä½ç§’ã€‚é»˜è®¤120ç§’ã€‚
        Returns:
            bool: å¦‚æœåœ¨è¶…æ—¶å‰åˆå§‹åŒ–å®Œæˆï¼Œè¿”å›Trueï¼›å¦åˆ™è¿”å›Falseã€‚
        """

        start_time = time.time()
        while True:
            with self._state_lock:
                if self._initialized:
                    return True
            if time.time() - start_time > timeout:
                return False
            time.sleep(0.1)


    def start(self) -> bool:
        """
        å¯åŠ¨è¯†åˆ«å™¨ï¼Œåˆå§‹åŒ–æ‘„åƒå¤´ä¸æ¨¡å‹ï¼Œå¹¶å¼€å¯åå°çº¿ç¨‹ã€‚
        
        Returns:
            bool: å¦‚æœæˆåŠŸå¯åŠ¨è¿”å› Trueï¼Œå¦‚æœå·²ç»åœ¨è¿è¡Œåˆ™è¿”å› False
        """
        # é˜²æ­¢é‡å¤å¯åŠ¨
        if self._capture_thread is not None and self._capture_thread.is_alive():
            logger.warning("è¯†åˆ«å™¨å·²ç»åœ¨è¿è¡Œä¸­ï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
            return False
        
        # åˆå§‹åŒ–æ‘„åƒå¤´ä¸æ¨¡å‹
        if not self._init_camera() or not self._init_model():
            logger.error("åˆå§‹åŒ–å¤±è´¥")
            raise Exception("æ‘„åƒå¤´æˆ–æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            # return False

        # é‡ç½®çŠ¶æ€
        self._stop_event.clear()
        # å¯åŠ¨é‡‡é›†çº¿ç¨‹
        self._capture_thread = threading.Thread(target=self._capture_loop, daemon=True)
        self._capture_thread.start()
        # å¯åŠ¨æ¨ç†çº¿ç¨‹
        self._infer_thread = threading.Thread(target=self._infer_loop, daemon=True)
        self._infer_thread.start()

        logger.info("è¯†åˆ«å™¨å¯åŠ¨ä¸­...")
        return True


    def stop(self) -> None:
        """
        åœæ­¢è¯†åˆ«å™¨ï¼Œç»ˆæ­¢åå°çº¿ç¨‹ã€‚
        """

        self._stop_event.set()
        if self._capture_thread and self._capture_thread.is_alive():
            self._capture_thread.join(timeout=2.0)
        if self._infer_thread and self._infer_thread.is_alive():
            self._infer_thread.join(timeout=2.0)
        
        with self._state_lock:
            self._initialized = False
        
        logger.info("è¯†åˆ«å™¨å·²åœæ­¢")


    def clean_up(self) -> None:
        """é‡Šæ”¾èµ„æºï¼Œå…³é—­æ‘„åƒå¤´ä¸çª—å£ã€‚"""
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        cv2.destroyAllWindows()


    def get_latest_boxes(self) -> Boxes:
        """
        è·å–æœ€æ–°çš„è¾¹ç•Œæ¡†ã€‚
        Returns:
            Boxes: æœ€æ–°çš„è¾¹ç•Œæ¡†å¯¹è±¡
        """
        with self._state_lock:
            return self._latest_boxes


    def _init_camera(self) -> bool:
        """åˆå§‹åŒ–æ‘„åƒå¤´ï¼Œè®¾ç½®åˆ†è¾¨ç‡ä¸å¸§ç‡ã€‚"""
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            logger.error("æ‘„åƒå¤´æœªæ‰“å¼€")
            return False

        # æ€§èƒ½ä¼˜åŒ–ï¼šå¯ç”¨ç¡¬ä»¶åŠ é€Ÿ
        try:
            self.cap.set(cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY)
        except:
            pass  # ç¡¬ä»¶åŠ é€Ÿä¸æ”¯æŒæ—¶é™é»˜å¿½ç•¥
        
        # ä¼˜åŒ–ï¼šå‡å°‘ç¼“å†²åŒºå»¶è¿Ÿ
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # è®¾ç½®åˆ†è¾¨ç‡å’Œå¸§ç‡
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.cam_width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.cam_height)
        self.cap.set(cv2.CAP_PROP_FPS, self.cam_fps)
        
        # ä¼˜åŒ–ï¼šä½¿ç”¨ MJPEG æ ¼å¼å‡å°‘è§£ç å¼€é”€
        try:
            self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M','J','P','G')) # type: ignore
        except:
            pass  # MJPEG ä¸æ”¯æŒæ—¶é™é»˜å¿½ç•¥

        # æµ‹è¯•æ‘„åƒå¤´æ˜¯å¦æ­£å¸¸å·¥ä½œ
        for i in range(10):
            ret, _ = self.cap.read()
        if not ret: # type: ignore
            logger.error("æ‘„åƒå¤´æœªè¯»å–åˆ°å¸§")
            self.cap.release()
            self.cap = None
            return False

        logger.info(f"æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆ: {self.cam_width}x{self.cam_height}@{self.cam_fps}fps")
        return True


    def _init_model(self) -> bool:
        """åˆå§‹åŒ–YOLOæ¨¡å‹ï¼ˆONNX Runtime åç«¯ï¼‰ã€‚"""
        try:
            # åˆå§‹åŒ–æ¨¡å‹
            self.model = YOLO(self.model_path, task="detect")
            
            # ä½¿ç”¨è™šæ‹Ÿå›¾åƒé¢„çƒ­
            dummy_frame = np.zeros((self.cam_height, self.cam_width, 3), dtype=np.uint8)
            for i in range(3):
                self.model.predict(dummy_frame, verbose=False)
            
            logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ: {self.model_path}")
            return True
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.error("è¯·ç¡®ä¿å·²å¯¼å‡º ONNX æ¨¡å‹: python tools/export_onnx_optimized.py")
            self.model = None
            return False


    def _capture_loop(self) -> None:
        """é‡‡é›†çº¿ç¨‹ï¼šä¸“æ³¨é«˜é¢‘é‡‡é›†ï¼Œç›´æ¥å°†å¸§æ”¾å…¥é˜Ÿåˆ—"""
        # æ€§èƒ½ä¼˜åŒ–ï¼šç»‘å®šåˆ° CPU æ ¸å¿ƒ 0
        try:
            import os
            os.sched_setaffinity(0, {0}) # type: ignore
        except Exception:
            pass  # CPU ç»‘å®šå¤±è´¥æ—¶é™é»˜å¿½ç•¥
        
        while not self._stop_event.is_set():
            if self.cap is None:
                time.sleep(0.1)  # æ‘„åƒå¤´æœªæ‰“å¼€æ—¶ä¼‘çœ è¾ƒé•¿æ—¶é—´ï¼ˆ100msï¼‰
                continue
                
            ret, frame = self.cap.read()
            if ret:
                try:
                    # å¦‚æœé˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒæ—§å¸§
                    if self._frame_queue.full():
                        try:
                            self._frame_queue.get_nowait()
                        except queue.Empty:
                            pass
                    self._frame_queue.put_nowait(frame)
                except queue.Full:
                    pass  # é˜Ÿåˆ—æ»¡æ—¶é™é»˜ä¸¢å¼ƒå½“å‰å¸§
            else:
                time.sleep(0.1)  # é‡‡é›†å¤±è´¥æ—¶ä¼‘çœ è¾ƒé•¿æ—¶é—´ï¼ˆ100msï¼Œå¼‚å¸¸æƒ…å†µï¼‰


    def _infer_loop(self) -> None:
        """
        æ¨ç†çº¿ç¨‹ï¼šæ¨¡å‹é¢„çƒ­ + æ™ºèƒ½è·³å¸§ç­–ç•¥ + æœ€å¤§é€Ÿåº¦æ¨ç†
        
        æµç¨‹ï¼š
        1. ç­‰å¾…é¦–å¸§ç”¨äºé¢„çƒ­
        2. ä½¿ç”¨çœŸå®å¸§é¢„çƒ­æ¨¡å‹ï¼ˆ3 æ¬¡æ¨ç†ï¼‰
        3. æ¸…ç©ºé¢„çƒ­æœŸé—´çš„æ—§å¸§
        4. è®¾ç½®å°±ç»ªæ ‡å¿—
        5. å¼€å§‹æ­£å¸¸æ¨ç†ï¼ˆæ™ºèƒ½è·³å¸§ + æœ€å¤§é€Ÿåº¦ï¼‰
        """
        # æ€§èƒ½ä¼˜åŒ–ï¼šç»‘å®šåˆ° CPU æ ¸å¿ƒ 2-3ï¼ˆæ€§èƒ½æ ¸å¿ƒï¼‰
        try:
            import os
            os.sched_setaffinity(0, {2, 3}) # type: ignore
        except Exception:
            pass  # CPU ç»‘å®šå¤±è´¥æ—¶é™é»˜å¿½ç•¥
        
        # ============================================================
        # é˜¶æ®µ 1ï¼šæ¨¡å‹é¢„çƒ­ï¼ˆè§£å†³é¦–æ¬¡æ¨ç†å»¶è¿Ÿé—®é¢˜ï¼‰
        # ============================================================
        
        # ç­‰å¾…é‡‡é›†çº¿ç¨‹æä¾›é¦–å¸§
        warmup_frame = None
        while warmup_frame is None and not self._stop_event.is_set():
            try:
                warmup_frame = self._frame_queue.get(timeout=0.5)
            except queue.Empty:
                continue
        
        if warmup_frame is None:
            logger.error("æœªèƒ½è·å–é¢„çƒ­å¸§ï¼Œæ¨ç†çº¿ç¨‹é€€å‡º")
            return
        
        # ä½¿ç”¨çœŸå®å¸§é¢„çƒ­æ¨¡å‹ï¼ˆ3 æ¬¡æ¨ç†ï¼‰
        logger.info("æ­£åœ¨é¢„çƒ­æ¨¡å‹ï¼ˆé¦–æ¬¡éœ€è¦ 5-10 ç§’ï¼‰...")
        try:
            for i in range(3):
                self.model.predict(warmup_frame, conf=self.conf, iou=self.iou, verbose=False) # type: ignore
        except Exception as e:
            logger.error(f"æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # æ¸…ç©ºé¢„çƒ­æœŸé—´ç§¯ç´¯çš„æ—§å¸§
        while not self._frame_queue.empty():
            try:
                self._frame_queue.get_nowait()
            except queue.Empty:
                break
        
        # è®¾ç½®å°±ç»ªæ ‡å¿—ï¼ˆwait_until_initialized ä¼šè¿”å›ï¼‰
        with self._state_lock:
            self._initialized = True
        
        # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å¹³å‡ FPSï¼‰
        self._inference_start_time = time.time()
        logger.info("è¯†åˆ«å™¨å°±ç»ªï¼Œå¼€å§‹æ¨ç†")
        
        # ============================================================
        # é˜¶æ®µ 2ï¼šæ­£å¸¸æ¨ç†å¾ªç¯ï¼ˆæ™ºèƒ½è·³å¸§ + æœ€å¤§é€Ÿåº¦ï¼‰
        # ============================================================
        
        while not self._stop_event.is_set():
            try:
                # ç­–ç•¥ï¼šå®Œå…¨éé˜»å¡è½®è¯¢ï¼ˆæ€§èƒ½æœ€ä½³ï¼‰
                # è¯Šæ–­æµ‹è¯•æ˜¾ç¤ºï¼šå®Œå…¨éé˜»å¡èƒ½è¾¾åˆ° 4.02 FPSï¼Œç©ºé˜Ÿåˆ—æ¬¡æ•°ä¸º 0
                # è¯´æ˜æ¨ç†é€Ÿåº¦è·Ÿå¾—ä¸Šé‡‡é›†é€Ÿåº¦ï¼Œæ— éœ€ sleep
                
                frame = None
                dropped_count = 0
                
                # éé˜»å¡åœ°æ¸…ç©ºé˜Ÿåˆ—ï¼Œåªä¿ç•™æœ€æ–°å¸§
                while not self._frame_queue.empty():
                    try:
                        frame = self._frame_queue.get_nowait()
                        dropped_count += 1
                    except queue.Empty:
                        break
                
                if frame is not None:
                    # æœ‰å¸§ï¼Œç«‹å³æ¨ç†
                    if dropped_count > 0:
                        self._dropped_frame_count += (dropped_count - 1)
                    self._process_frame(frame)
                    self._last_inference_time = time.time()
                # else: é˜Ÿåˆ—ç©ºæ—¶ç»§ç»­è½®è¯¢ï¼ˆæ—  sleepï¼‰
                # è¯Šæ–­æ˜¾ç¤ºç©ºé˜Ÿåˆ—æ¬¡æ•°ä¸º 0ï¼Œè¯´æ˜æ¨ç†é€Ÿåº¦è·Ÿå¾—ä¸Š
                    
            except Exception as e:
                logger.error(f"æ¨ç†å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(0.1)


    def _process_frame(self, frame: cv2.typing.MatLike) -> None:
        """å¤„ç†å•å¸§ï¼šæ¨ç† + ç”Ÿæˆæ³¨é‡Šå¸§ + æ›´æ–°ç»“æœ"""
        if self.model is None:
            return
            
        try:
            # æ‰§è¡Œæ¨ç†
            results = self.model.predict(
                source=frame,
                conf=self.conf,
                iou=self.iou,
                verbose=False  # å‡å°‘æ—¥å¿—è¾“å‡º
            )
            
            # ç”Ÿæˆå¸¦æ³¨é‡Šçš„å¸§ç”¨äºæ˜¾ç¤º
            if IF_ANNOTATE:
                self.current_annotated_frame = results[0].plot()

            # æå–è¾¹ç•Œæ¡†
            boxes = results[0].boxes
            if boxes is None:
                boxes = Boxes(np.empty((0, 6)), orig_shape=(self.cam_height, self.cam_width))
            boxes = boxes.cpu()
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœ
            with self._state_lock:
                self._latest_boxes = boxes

            self._predict_frame_count += 1
                
        except Exception as e:
            logger.error(f"å¸§å¤„ç†å¤±è´¥: {e}")



    def imshow(self, win_name: str = "Recognizer", wait: int = 1) -> None:
        """
        è°ƒè¯•ç”¨ï¼šå±•ç¤ºæ¨ç†å¸§ï¼ˆå¸¦æ³¨é‡Šï¼‰æˆ–åŸå§‹å¸§ã€‚
        """

        if not IF_IMSHOW:
            return

        # ä¼˜å…ˆæ˜¾ç¤ºæ¨ç†å¸§ï¼Œå¦åˆ™å°è¯•è·å–é˜Ÿåˆ—ä¸­çš„åŸå§‹å¸§
        if self.current_annotated_frame is not None:
            imshow_frame = cv2.resize(self.current_annotated_frame, (self.imshow_width, self.imshow_height))
            cv2.imshow(win_name, imshow_frame)
            cv2.waitKey(wait)
        elif not self._frame_queue.empty():
            try:
                frame = self._frame_queue.queue[0]  # æŸ¥çœ‹é˜Ÿåˆ—ä¸­çš„å¸§ä½†ä¸å–å‡º
                cv2.imshow(win_name, frame)
                cv2.waitKey(wait)
            except:
                logger.warning("æ— å¯æ˜¾ç¤ºå¸§")
        else:
            logger.warning("æ— å¯æ˜¾ç¤ºå¸§")
