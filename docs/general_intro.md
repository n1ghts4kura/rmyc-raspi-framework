---
scope: overview
period: v1.0 - v1.1_re
llm_summary: >-
  本文是整个 RoboMaster 树莓派控制框架的总览说明，
  重点描述项目目标、硬件/运行环境、三层软件架构、
  各核心子系统的职责与协作方式，以及与文档系统的关系。
entry_points:
  - src/
  - docs/index.md
  - docs/status.md
  - docs/plans.md
---

# 项目总体介绍（General Intro）

> 本文面向**首次接触本项目**的开发者与 LLM，目标是在一次连续阅读中，帮助你建立清晰的整体心智模型：
> - 这个项目要解决什么问题，在什么硬件环境下运行；
> - 软件是如何分层的，各层大致负责什么；
> - 各核心子系统（通信、视觉、自瞄、技能、REPL）如何协作；
> - 本文与 `docs/` 下其他文档的分工关系与推荐阅读路径。
>
> 注意：本文只描述**当前已经存在或正在演进中的事实**，不会预先承诺尚未实现的能力。

---

## 1. 项目目标与运行场景

本项目是一个运行在 **树莓派 + RoboMaster S1/EP** 组合上的机器人控制框架，目标是：

- 在树莓派上通过串口与 RoboMaster 机器人通信；
- 提供一套**可复用的硬件抽象接口**（底盘、云台、发射器等），方便快速开发不同玩法；
- 集成视觉识别与基础自瞄能力，支持在比赛 / 实验场景中进行自动瞄准与射击；
- 通过技能系统与 REPL，为后续功能扩展、参数调试、教学演示提供基础设施。

### 1.1 典型部署拓扑

典型的物理连接关系如下（简化示意）：

- 树莓派 4B：
  - 通过 USB‑转‑串口（或直接 USB）连接 RoboMaster EP/S1 的上位机接口；
  - 通过 USB 摄像头或机器人自带摄像头采集画面；
- RoboMaster EP/S1：
  - 运行官方 RoboMaster 系统，通过 SDK 协议响应来自树莓派的控制指令；
- 开发机（笔记本 / 台式机）：
  - 主要用于编辑代码与通过 SSH 登录树莓派；
  - **不作为正式验证平台**（不会在开发机上声明“功能已在实机环境通过验证”）。

### 1.2 版本线索（简要）

更详细的历史可以在 `docs/journey/v1_0_history.md` 中查看，这里只给出一个极简时间线，帮助理解当前代码所处阶段：

- **v1.0**：
  - 完成串口通信与基本硬件抽象（`src/bot/`）；
  - 实现了基础技能系统与 REPL 调试工具；
  - 视觉识别与自瞄只具备最基础功能。
- **v1.1**：
  - 引入更完整的自瞄模块（`src/aimassistant/`）；
  - 对性能与参数管理做了一轮集中优化；
- **v1.1_re（当前分支 dev_v1_1_re）**：
  - 重点放在文档体系重建与结构梳理；
  - 同时为后续功能演进预留清晰的架构与文档入口。

关于“当前能用什么、哪些仍在开发中”的更细节说明，请参考 `docs/status.md` 与 `docs/plans.md`。

---

## 2. 硬件与软件运行环境

本项目的设计假设如下：

### 2.1 硬件与系统假设

- **树莓派型号**：以 Raspberry Pi 4B 为主要参考（其他型号需要根据性能自行评估）。
- **操作系统**：Raspberry Pi OS 或其他类 Debian Linux 发行版。
- **机器人平台**：DJI RoboMaster S1 或 EP（以 EP 为主要参考）。
- **串口设备路径**：
  - 在树莓派上通常为 `/dev/ttyUSB0` 或类似设备名；
  - 串口号在不同设备与接线方式下可能变化，应通过实际检测确认。
- **摄像头**：
  - 可以是 USB 摄像头，也可以是机器人本体摄像头（取决于具体接入方式）；
  - 具体采集方式由 `src/recognizer.py` 与相关配置决定。

### 2.2 软件与依赖

- **Python 版本**：Python 3.10 及以上（以仓库当前使用版本为准）。
- **主要第三方库**：
  - OpenCV：用于图像采集与基础图像处理；
  - ONNX Runtime：用于加载和推理 YOLOv8 ONNX 模型；
  - PySerial：用于串口通信；
  - 其他依赖见项目根目录下的 `requirements.txt`。 

### 2.3 开发机与验证平台的区分

- 开发机（Windows / Linux / macOS）主要用于：
  - 编辑代码、运行静态检查工具；
  - 通过 SSH 登录树莓派进行远程开发；
- **正式功能验证必须在“树莓派 + RoboMaster 实机”环境中完成**：
  - 文档中的“已验证”结论，默认指在目标硬件上的实测结果；
  - 不会以“在开发机上跑通脚本”作为验证依据。

关于当前具体的验证状态与已知问题，请参考 `docs/status.md` 中的描述。

---

## 3. 软件总体架构分层

从软件视角来看，本项目大致采用了三层结构：

1. **硬件抽象层（HAL）：`src/bot/` 与基础通信模块；
2. **业务逻辑层**：自瞄、视觉识别、技能系统等；
3. **应用与工具层**：主程序 `main.py` 与 REPL `repl.py`。

下文会按这三层分别介绍。

### 3.1 硬件抽象层：`src/bot/` 及通信基础

这一层负责把「串口 + SDK 协议」包装成一组可调用的 Python 接口，使上层完全不需要关心具体的协议格式与组包/拆包细节。

核心文件包括（非完整列表）：

- `src/bot/conn.py`
  - 负责与串口设备建立连接（通常是 `/dev/ttyUSB0`）；
  - 管理收发线程、命令队列以及基础的超时与错误处理；
- `src/bot/sdk.py`
  - 对 RoboMaster 官方 SDK 协议进行封装；
  - 提供“发送某类命令”的高层接口（例如控制云台、底盘、发射器等）；
- `src/bot/robot.py`
  - 作为“机器人对象”的聚合入口，组合底盘、云台、发射器等子模块；
- `src/bot/chassis.py`
  - 提供底盘运动控制接口（如设置速度、旋转等）；
- `src/bot/gimbal.py`
  - 提供云台控制接口，包括角度设定、速度控制等；
- `src/bot/blaster.py`
  - 控制发射器（开火/停火等动作）；
- `src/bot/game_msg.py`
  - 处理比赛相关或上报类消息（如有使用）。

这一层的设计目标是：

- **对上层提供稳定、简单、带参数校验的 Python API**；
- **对下层屏蔽串口与协议细节**，包括：
  - 指令打包与解析；
  - 命令发送与重试；
  - 基础的错误检测与日志记录。

### 3.2 业务逻辑层：自瞄、视觉与技能

这一层是在硬件抽象之上，围绕“机器人要做什么”展开的逻辑，包括视觉识别、自瞄决策和按键触发的技能等。

#### 3.2.1 视觉识别：`src/recognizer.py`

- 职责：
  - 管理摄像头采集线程；
  - 加载 YOLOv8 ONNX 模型并执行推理；
  - 将识别结果（例如目标框、置信度等）整理成上层易于消费的数据结构。
- 典型流程：
  1. 初始化摄像头与推理引擎；
  2. 以一定频率采集图像帧，进行预处理（如缩放、格式转换）；
  3. 调用 ONNX Runtime 进行推理，得到识别结果；
  4. 将结果提供给自瞄模块或其他需要视觉信息的部分。

该模块属于性能敏感区域，需要在“正确性优先”的前提下关注帧率与延迟。更细的性能演进与坑点，未来会在 `docs/journey/vision_recognition_journey.md` 中记录。

#### 3.2.2 自瞄系统：`src/aimassistant/`

- 模块组成：
  - `angle.py`：角度与坐标相关的计算工具，例如根据目标位置与相机参数估算需要调整的云台角度；
  - `selector.py`：从多个候选目标中选择当前要瞄准的目标（根据距离、位置、优先级等策略）；
  - `pipeline.py`：串联视觉识别结果、目标选择与云台控制/发射控制，形成自瞄流程。
- 职责概述：
  - 订阅来自 `recognizer` 的目标检测结果；
  - 根据当前云台姿态、目标位置和相机视场等信息，计算应当调整的角度；
  - 通过 `src/bot/gimbal.py` 与 `src/bot/blaster.py` 发送控制命令，实现“朝向目标并在合适时机发射”。

当前自瞄系统已经具备基础闭环框架，但策略、参数与鲁棒性仍在持续打磨中。针对“自瞄为何这样设计、经历过哪些方案”的历史与经验，会在 `docs/journey/aimassistant_journey.md` 中详细展开。

#### 3.2.3 技能系统：`src/skill/`

技能系统为「一组可开关、可组合的行为」提供统一框架，典型场景包括：

- 手动按键触发某种移动或自瞄行为；
- 为比赛策略封装成一个个可复用“技能”；
- 方便在 `main.py` 中注册和管理不同技能的生命周期。

关键文件：

- `src/skill/base_skill.py`
  - 定义技能的基类接口，例如启用/停用、执行线程等；
- `src/skill/manager.py`
  - 负责管理多个技能实例，处理按键/事件映射；
- `src/skill/example_skill.py`
  - 示例技能，用于演示如何实现一个具体技能；
- `src/skill/autoaim.py`
  - 与自瞄相关的技能封装，通常会调用 `aimassistant` 与 `bot` 层接口。

这一层与 `bot`、`aimassistant` 的关系可以粗略理解为：

- `bot` 提供“能做什么”的原子动作（移动、转向、发射等）；
- `aimassistant` 决定“如何对准目标”；
- `skill` 决定“在什么时候、在什么输入下触发哪些行为组合”。

### 3.3 应用与工具层：主程序与 REPL

这一层是用户直接运行的入口。

#### 3.3.1 主程序：`src/main.py`

- 启动顺序大致包括：
  - 初始化日志与全局配置（例如 `src/config.py`）；
  - 建立与机器人之间的连接（通过 `src/bot/`）；
  - 初始化识别模块、自瞄模块与技能管理器；
  - 注册需要的技能，并进入主循环或事件驱动逻辑。
- 主程序是“把各子系统接到一起”的地方，负责：
  - 决定哪些子系统在当前运行模式下被启用；
  - 处理键盘/手柄/网络等输入事件（视实现而定）；
  - 维护整个应用生命周期（启动、运行、退出）。

#### 3.3.2 REPL 调试工具：`src/repl.py`

- 作用：
  - 提供交互式命令行环境，方便直接向机器人发送命令、观察反馈；
  - 在集成进主程序之前，先在 REPL 中验证某个硬件控制函数或协议细节是否正确。
- 使用原则：
  - 对新的硬件控制逻辑，优先在 REPL 中做“烟雾测试”；
  - 只有在 REPL 中确认行为符合预期后，才将其封装进 `bot/` 模块或更高层逻辑；
  - 这有助于把“通信/协议问题”与“业务逻辑问题”分离，便于排错。

更具体的 REPL 使用方法与命令说明，请参考 `docs/repl.md`（如已存在）。

---

## 4. 配置与日志（简要）

虽然本文不打算展开所有配置项的细节，但有两个模块在理解整体行为时非常关键：

- `src/config.py`
  - 集中定义串口端口号、波特率、模型路径、相机分辨率、自瞄相关参数等全局配置；
  - 通过“单一入口”的方式，避免配置散落在代码各处；
- `src/logger.py`
  - 统一项目日志输出风格与级别；
  - 用于在多线程环境中记录关键行为与异常，便于事后追踪问题。

当你需要调整串口端口、摄像头分辨率或自瞄参数时，优先查看 `src/config.py`；
当你需要理解“系统在运行时都做了什么”时，优先查看日志配置与实际日志输出。

---

## 5. 与文档系统的关系与阅读路径

`general_intro.md` 在整个 `docs/` 文档系统中的角色，可以理解为：

- **给新读者的第一站**：
  - 先帮助你知道“项目大概长什么样”；
  - 再由你根据兴趣与任务，跳转到更具体的文档。
- **给 LLM 的事实基线**：
  - 描述当前代码结构与模块职责的共识版本；
  - 当生成更细的文档时，应优先与本文件保持一致，如有冲突应以最新代码和 `status.md` 为准。

结合当前的文档结构，推荐的阅读路线大致是：

1. **第一次接触项目时**：
   - 先阅读本文件 `docs/general_intro.md`；
   - 然后根据需要阅读：
     - `docs/status.md`：当前功能完成度与已知问题；
     - `docs/plans.md`：后续演进计划与版本路线。  
2. **想深入某个子系统时**：
   - 如果已有对应的 `*_intro.md`（例如未来的 `aimassistant_intro.md`、`vision_intro.md`），先读 intro；
   - 如需了解历史与坑点，再读对应的 `docs/journey/*.md` 文档；
   - 同时配合阅读相关源码（例如 `src/aimassistant/`、`src/recognizer.py`）。
3. **需要排查复杂问题或规划重构时**：
   - 先通过本文件和 `status.md` 找到相关子系统；
   - 再阅读对应的 journey 文档（例如 `docs/journey/v1_0_history.md`、未来的 `aimassistant_journey.md` 等），了解历史决策与既有坑点；
   - 最后再回到源码与配置做具体调整。

随着项目演进，如果文档结构有较大调整，应同步更新本节中的阅读建议。

---

## 6. 当前局限与后续扩展方向

从当前代码与文档状态来看，本项目仍处于持续演进阶段，存在一些需要注意的局限与改进方向：

### 6.1 已知局限（高层视角）

- **自动化测试体系仍然缺失**：
  - 目前主要依赖人工在目标硬件上的验证；
  - 对于协议变更、性能优化等改动，缺少系统化的回归测试。
- **文档与实现之间仍需持续同步**：
  - 本文件及 `docs/` 下其他文档刚经历一次集中重构；
  - 未来每次对核心模块（通信、自瞄、视觉、技能）的重要更改，都需要同步更新相关 intro/journey 文档。
- **部分模块仍在打磨中**：
  - 自瞄策略与参数尚在不断迭代；
  - 视觉识别链路（模型、预处理、线程结构）也有进一步优化空间；
  - 这些内容会在后续 journey 文档中有更细致的记录。

### 6.2 建议的后续扩展方向

以下建议并不是“必须立即完成的任务”，而是面向未来维护者的方向性提示：

- **补充模块级 intro 文档**：
  - 如 `aimassistant_intro.md`、`vision_intro.md`、`bot_intro.md`、`skill_intro.md` 等；
  - 让每个主要子系统都有一份清晰的、面向开发者的设计说明。
- **为关键模块编写 journey 文档**：
  - 例如 `docs/journey/aimassistant_journey.md`、`docs/journey/uart_communication_journey.md`、`docs/journey/vision_recognition_journey.md`；
  - 把性能调优、故障排查与设计取舍过程系统化记录下来。
- **逐步引入自动化测试与验证脚本**：
  - 从通信层与关键数学计算（如角度转换）入手，先补一批可在开发机运行的单元测试；
  - 再考虑在树莓派上运行的集成级测试脚本。
- **围绕 REPL 与技能系统沉淀更多示例**：
  - 使用 REPL 演示常见“从 0 到 1”的调试流程；
  - 提供若干有代表性的技能示例，帮助新手快速掌握项目用法。

这些方向在 `docs/plans.md` 中会有更细致的拆解与优先级安排，本节只做高层概述。

---

> 总结：
> - 如果你只打算花十几分钟了解本项目，请至少完整阅读本文件；
> - 如果你准备真正参与开发，请在此基础上继续阅读 `status.md`、`plans.md` 与相关源码；
> - 如果你是 LLM，在生成更细粒度文档前，请优先将本文件与 `index.md` 作为“当前架构事实”的主要参考。